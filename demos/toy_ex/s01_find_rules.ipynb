{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8848979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, pathlib\n",
    "sys.path.insert(0, str(pathlib.Path.cwd().parent.parent))  # add repo root\n",
    "from tsum import tsum\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from ndtools import fun_binary_graph as fbg # ndtools available at github.com/jieunbyun/network-datasets\n",
    "from ndtools.graphs import build_graph\n",
    "from pathlib import Path\n",
    "import networkx as nx   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ffcf5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 2 status = s\n"
     ]
    }
   ],
   "source": [
    "DATASET = Path(\"data\") \n",
    "\n",
    "nodes = json.loads((DATASET / \"nodes.json\").read_text(encoding=\"utf-8\"))\n",
    "edges = json.loads((DATASET / \"edges.json\").read_text(encoding=\"utf-8\"))\n",
    "probs_dict = json.loads((DATASET / \"probs.json\").read_text(encoding=\"utf-8\"))\n",
    "\n",
    "# build base graph\n",
    "G_base: nx.Graph = build_graph(nodes, edges, probs_dict)\n",
    "\n",
    "# all edges ON (example); add node/edge 0s as needed\n",
    "states = {eid: 1 for eid in edges.keys()}\n",
    "\n",
    "k_val, status, _ = fbg.eval_global_conn_k(states, G_base, target_k=2)\n",
    "print(\"k =\", k_val, \"status =\", status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e38a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_fun = lambda comps_st: fbg.eval_global_conn_k(comps_st, G_base, target_k=2)\n",
    "row_names = list(edges.keys()) + ['sys']\n",
    "n_state = 2  # binary states: 0, 1\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "probs = [[probs_dict[n]['0']['p'], probs_dict[n]['1']['p']] for n in row_names[:-1]]\n",
    "probs = torch.tensor(probs, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42141858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 1, Unk. prob.: 1.000e+00\n",
      "No. of non-dominant rules: 0, Survival rules: 0, Failure rules: 0\n",
      "Survival sample found from survival rules 👍\n",
      "No. of existing rules removed:  0\n",
      "New rule added. System state: s, flow: 2. Total samples: 1024.\n",
      "New rule (No. of conditions: 11): {'e01': ('>=', 1), 'e02': ('>=', 1), 'e03': ('>=', 1), 'e04': ('>=', 1), 'e05': ('>=', 1), 'e06': ('>=', 1), 'e07': ('>=', 1), 'e08': ('>=', 1), 'e09': ('>=', 1), 'e10': ('>=', 1), 'e11': ('>=', 1), 'sys': ('>=', 1)}\n",
      "Updated sys_vals: [2]\n",
      "Failure sample found from failure rules 👍\n",
      "No. of existing rules removed:  0\n",
      "New rule added. System state: f, flow: 0. Total samples: 1024.\n",
      "New rule (No. of conditions: 11): {'e01': ('<=', 0), 'e02': ('<=', 0), 'e03': ('<=', 0), 'e04': ('<=', 0), 'e05': ('<=', 0), 'e06': ('<=', 0), 'e07': ('<=', 0), 'e08': ('<=', 0), 'e09': ('<=', 0), 'e10': ('<=', 0), 'e11': ('<=', 0), 'sys': ('<=', 0)}\n",
      "Unique system values: [2, 0]\n",
      "Round: 2, Unk. prob.: 1.000e+00\n",
      "No. of non-dominant rules: 2, Survival rules: 1, Failure rules: 1\n",
      "Failure sample found from survival rules 👍👍\n",
      "No. of existing rules removed:  1\n",
      "New rule added. System state: f, flow: 1. Total samples: 1024.\n",
      "New rule (No. of conditions: 1): {'e04': ('<=', 0), 'sys': ('<=', 0)}\n",
      "Updated sys_vals: [2, 1, 0]\n",
      "Failure sample found from failure rules 👍\n",
      "No. of existing rules removed:  0\n",
      "New rule added. System state: f, flow: 0. Total samples: 1024.\n",
      "New rule (No. of conditions: 10): {'e01': ('<=', 0), 'e02': ('<=', 0), 'e03': ('<=', 0), 'e05': ('<=', 0), 'e06': ('<=', 0), 'e07': ('<=', 0), 'e08': ('<=', 0), 'e09': ('<=', 0), 'e10': ('<=', 0), 'e11': ('<=', 0), 'sys': ('<=', 0)}\n",
      "Round: 3, Unk. prob.: 1.000e+00\n",
      "No. of non-dominant rules: 3, Survival rules: 1, Failure rules: 2\n",
      "Failure sample found from survival rules 👍👍\n",
      "No. of existing rules removed:  1\n",
      "New rule added. System state: f, flow: 1. Total samples: 1024.\n",
      "New rule (No. of conditions: 1): {'e03': ('<=', 0), 'sys': ('<=', 0)}\n",
      "Failure sample found from failure rules 👍\n",
      "No. of existing rules removed:  0\n",
      "New rule added. System state: f, flow: 0. Total samples: 1024.\n",
      "New rule (No. of conditions: 9): {'e01': ('<=', 0), 'e02': ('<=', 0), 'e05': ('<=', 0), 'e06': ('<=', 0), 'e07': ('<=', 0), 'e08': ('<=', 0), 'e09': ('<=', 0), 'e10': ('<=', 0), 'e11': ('<=', 0), 'sys': ('<=', 0)}\n",
      "Round: 4, Unk. prob.: 1.000e+00\n",
      "No. of non-dominant rules: 4, Survival rules: 1, Failure rules: 3\n",
      "Failure sample found from survival rules 👍👍\n",
      "No. of existing rules removed:  1\n",
      "New rule added. System state: f, flow: 1. Total samples: 1024.\n",
      "New rule (No. of conditions: 1): {'e08': ('<=', 0), 'sys': ('<=', 0)}\n",
      "Failure sample found from failure rules 👍\n",
      "No. of existing rules removed:  0\n",
      "New rule added. System state: f, flow: 0. Total samples: 1024.\n",
      "New rule (No. of conditions: 8): {'e01': ('<=', 0), 'e02': ('<=', 0), 'e05': ('<=', 0), 'e06': ('<=', 0), 'e07': ('<=', 0), 'e09': ('<=', 0), 'e10': ('<=', 0), 'e11': ('<=', 0), 'sys': ('<=', 0)}\n",
      "Round: 5, Unk. prob.: 1.000e+00\n",
      "No. of non-dominant rules: 5, Survival rules: 1, Failure rules: 4\n",
      "Survival sample found from survival rules 👍\n",
      "No. of existing rules removed:  1\n",
      "New rule added. System state: s, flow: 2. Total samples: 1024.\n",
      "New rule (No. of conditions: 10): {'e01': ('>=', 1), 'e02': ('>=', 1), 'e03': ('>=', 1), 'e04': ('>=', 1), 'e05': ('>=', 1), 'e06': ('>=', 1), 'e07': ('>=', 1), 'e08': ('>=', 1), 'e09': ('>=', 1), 'e11': ('>=', 1), 'sys': ('>=', 1)}\n",
      "Failure sample found from failure rules 👍\n",
      "No. of existing rules removed:  1\n",
      "New rule added. System state: f, flow: 0. Total samples: 1024.\n",
      "New rule (No. of conditions: 7): {'e01': ('<=', 0), 'e02': ('<=', 0), 'e06': ('<=', 0), 'e07': ('<=', 0), 'e09': ('<=', 0), 'e10': ('<=', 0), 'e11': ('<=', 0), 'sys': ('<=', 0)}\n",
      "Round: 6, Unk. prob.: 1.000e+00\n",
      "No. of non-dominant rules: 5, Survival rules: 1, Failure rules: 4\n",
      "Failure sample found from survival rules 👍👍\n",
      "No. of existing rules removed:  0\n",
      "New rule added. System state: f, flow: 1. Total samples: 1024.\n",
      "New rule (No. of conditions: 1): {'e05': ('<=', 0), 'sys': ('<=', 0)}\n",
      "Failure sample found from failure rules 👍\n",
      "No. of existing rules removed:  1\n",
      "New rule added. System state: f, flow: 0. Total samples: 1024.\n",
      "New rule (No. of conditions: 6): {'e01': ('<=', 0), 'e02': ('<=', 0), 'e06': ('<=', 0), 'e07': ('<=', 0), 'e10': ('<=', 0), 'e11': ('<=', 0), 'sys': ('<=', 0)}\n",
      "Round: 7, Unk. prob.: 1.000e+00\n",
      "No. of non-dominant rules: 6, Survival rules: 1, Failure rules: 5\n",
      "Failure sample found from survival rules 👍👍\n",
      "No. of existing rules removed:  1\n",
      "New rule added. System state: f, flow: 1. Total samples: 1024.\n",
      "New rule (No. of conditions: 1): {'e11': ('<=', 0), 'sys': ('<=', 0)}\n",
      "Failure sample found from failure rules 👍\n",
      "No. of existing rules removed:  0\n",
      "New rule added. System state: f, flow: 0. Total samples: 1024.\n",
      "New rule (No. of conditions: 6): {'e01': ('<=', 0), 'e02': ('<=', 0), 'e06': ('<=', 0), 'e07': ('<=', 0), 'e09': ('<=', 0), 'e10': ('<=', 0), 'sys': ('<=', 0)}\n",
      "Round: 8, Unk. prob.: 1.000e+00\n",
      "No. of non-dominant rules: 7, Survival rules: 1, Failure rules: 6\n",
      "Failure sample found from survival rules 👍👍\n",
      "No. of existing rules removed:  1\n",
      "New rule added. System state: f, flow: 1. Total samples: 1024.\n",
      "New rule (No. of conditions: 1): {'e02': ('<=', 0), 'sys': ('<=', 0)}\n",
      "Failure sample found from failure rules 👍\n",
      "No. of existing rules removed:  0\n",
      "New rule added. System state: f, flow: 0. Total samples: 1024.\n",
      "New rule (No. of conditions: 5): {'e01': ('<=', 0), 'e06': ('<=', 0), 'e07': ('<=', 0), 'e09': ('<=', 0), 'e10': ('<=', 0), 'sys': ('<=', 0)}\n",
      "Round: 9, Unk. prob.: 1.000e+00\n",
      "No. of non-dominant rules: 8, Survival rules: 1, Failure rules: 7\n",
      "Survival sample found from survival rules 👍\n",
      "No. of existing rules removed:  0\n",
      "New rule added. System state: s, flow: 2. Total samples: 1024.\n",
      "New rule (No. of conditions: 10): {'e01': ('>=', 1), 'e02': ('>=', 1), 'e03': ('>=', 1), 'e04': ('>=', 1), 'e05': ('>=', 1), 'e07': ('>=', 1), 'e08': ('>=', 1), 'e09': ('>=', 1), 'e10': ('>=', 1), 'e11': ('>=', 1), 'sys': ('>=', 1)}\n",
      "Failure sample found from failure rules 👍\n",
      "No. of existing rules removed:  1\n",
      "New rule added. System state: f, flow: 1. Total samples: 1024.\n",
      "New rule (No. of conditions: 4): {'e01': ('<=', 0), 'e06': ('<=', 0), 'e07': ('<=', 0), 'e10': ('<=', 0), 'sys': ('<=', 0)}\n",
      "Round: 10, Unk. prob.: 1.000e+00\n",
      "No. of non-dominant rules: 9, Survival rules: 2, Failure rules: 7\n",
      "Survival sample found from survival rules 👍\n",
      "No. of existing rules removed:  1\n",
      "New rule added. System state: s, flow: 2. Total samples: 1024.\n",
      "New rule (No. of conditions: 9): {'e02': ('>=', 1), 'e03': ('>=', 1), 'e04': ('>=', 1), 'e05': ('>=', 1), 'e06': ('>=', 1), 'e07': ('>=', 1), 'e08': ('>=', 1), 'e09': ('>=', 1), 'e11': ('>=', 1), 'sys': ('>=', 1)}\n",
      "Failure sample found from failure rules 👍\n",
      "No. of existing rules removed:  0\n",
      "New rule added. System state: f, flow: 0. Total samples: 1024.\n",
      "New rule (No. of conditions: 4): {'e06': ('<=', 0), 'e07': ('<=', 0), 'e09': ('<=', 0), 'e10': ('<=', 0), 'sys': ('<=', 0)}\n",
      "Round: 11, Unk. prob.: 1.000e+00\n",
      "No. of non-dominant rules: 10, Survival rules: 2, Failure rules: 8\n",
      "Failure sample found from survival rules 👍👍\n",
      "No. of existing rules removed:  2\n",
      "New rule added. System state: f, flow: 1. Total samples: 1024.\n",
      "New rule (No. of conditions: 1): {'e07': ('<=', 0), 'sys': ('<=', 0)}\n",
      "Failure sample found from failure rules 👍\n",
      "No. of existing rules removed:  0\n",
      "New rule added. System state: f, flow: 1. Total samples: 1024.\n",
      "New rule (No. of conditions: 4): {'e01': ('<=', 0), 'e06': ('<=', 0), 'e09': ('<=', 0), 'e10': ('<=', 0), 'sys': ('<=', 0)}\n",
      "Round: 12, Unk. prob.: 1.000e+00\n",
      "No. of non-dominant rules: 10, Survival rules: 2, Failure rules: 8\n",
      "Failure sample found from survival rules 👍👍\n",
      "No. of existing rules removed:  1\n",
      "New rule added. System state: f, flow: 1. Total samples: 1024.\n",
      "New rule (No. of conditions: 1): {'e09': ('<=', 0), 'sys': ('<=', 0)}\n",
      "Survival sample found from failure rules 👍👍\n",
      "No. of existing rules removed:  2\n",
      "New rule added. System state: s, flow: 2. Total samples: 1024.\n",
      "New rule (No. of conditions: 8): {'e02': ('>=', 1), 'e03': ('>=', 1), 'e04': ('>=', 1), 'e05': ('>=', 1), 'e07': ('>=', 1), 'e08': ('>=', 1), 'e09': ('>=', 1), 'e11': ('>=', 1), 'sys': ('>=', 1)}\n",
      "Round: 13, Unk. prob.: 1.000e+00\n",
      "No. of non-dominant rules: 9, Survival rules: 1, Failure rules: 8\n",
      "Max iterations reached without finding a valid sample.\n",
      "Max iterations reached without finding a valid sample.\n",
      "[Final results] Probs: 'surv':  1.673e-01, 'fail':  8.327e-01, 'unkn':  0.000e+00\n"
     ]
    }
   ],
   "source": [
    "result = tsum.run_rule_extraction(\n",
    "    # Problem-specific callables / data\n",
    "    sfun=s_fun,\n",
    "    probs=probs,\n",
    "    row_names=row_names,\n",
    "    n_state=n_state,\n",
    "    output_dir=\"toy_tsum\",\n",
    "    surv_json_name=\"rules_surv.json\",\n",
    "    fail_json_name=\"rules_fail.json\"\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fe8598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "def classify_samples_with_indices(\n",
    "    samples: torch.Tensor,\n",
    "    survival_rules: List[torch.Tensor],\n",
    "    failure_rules: List[torch.Tensor],\n",
    "    *,\n",
    "    return_masks: bool = False\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Classify samples as survival, failure, or unknown using subset checks,\n",
    "    and return indices for each class.\n",
    "\n",
    "    Args:\n",
    "        samples: (n_sample, n_var, n_state) binary tensor\n",
    "        survival_rules: list of rule tensors, each (n_var, n_state) or (n_var+1, n_state)\n",
    "        failure_rules: list of rule tensors, each (n_var, n_state) or (n_var+1, n_state)\n",
    "        return_masks: if True, also return boolean masks per class\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "          'survival': int,\n",
    "          'failure' : int,\n",
    "          'unknown' : int,\n",
    "          'idx_survival': LongTensor[ns],\n",
    "          'idx_failure' : LongTensor[nf],\n",
    "          'idx_unknown' : LongTensor[nu],\n",
    "          # optionally:\n",
    "          'mask_survival': BoolTensor[n_sample],\n",
    "          'mask_failure' : BoolTensor[n_sample],\n",
    "          'mask_unknown' : BoolTensor[n_sample],\n",
    "        }\n",
    "    \"\"\"\n",
    "    device = samples.device\n",
    "    n_sample = samples.shape[0]\n",
    "\n",
    "    # Tracking masks\n",
    "    classified = torch.zeros(n_sample, dtype=torch.bool, device=device)\n",
    "    survival_mask = torch.zeros(n_sample, dtype=torch.bool, device=device)\n",
    "    failure_mask = torch.zeros(n_sample, dtype=torch.bool, device=device)\n",
    "\n",
    "    # Build (rule_tensor, label) list; drop system row if requested\n",
    "    def _prep_rules(rules, label):\n",
    "        out = []\n",
    "        for r in rules:\n",
    "            r_ok = r[:-1, :]\n",
    "            out.append((r_ok.to(device=device, dtype=torch.bool), label))\n",
    "        return out\n",
    "\n",
    "    all_rules = _prep_rules(survival_rules, 'survival') + _prep_rules(failure_rules, 'failure')\n",
    "\n",
    "    # Classification loop\n",
    "    samples_b = samples.to(device=device, dtype=torch.bool)\n",
    "    for rule_tensor, label in all_rules:\n",
    "        unclassified_idx = ~classified\n",
    "        if not unclassified_idx.any():\n",
    "            break\n",
    "\n",
    "        current_samples = samples_b[unclassified_idx]  # (n_curr, n_var, n_state)\n",
    "        # Subset check: sample ⊆ rule  <=>  (sample & rule) == sample  across (var, state)\n",
    "        is_subset = torch.all((current_samples & rule_tensor) == current_samples, dim=(1, 2))\n",
    "\n",
    "        # Map back to original indices\n",
    "        idx_all = torch.where(unclassified_idx)[0]\n",
    "        matched_idx = idx_all[is_subset]\n",
    "\n",
    "        if matched_idx.numel() == 0:\n",
    "            continue\n",
    "\n",
    "        if label == 'survival':\n",
    "            survival_mask[matched_idx] = True\n",
    "        else:\n",
    "            failure_mask[matched_idx] = True\n",
    "\n",
    "        classified[matched_idx] = True\n",
    "\n",
    "    unknown_mask = ~classified\n",
    "\n",
    "    # Indices\n",
    "    idx_survival = torch.where(survival_mask)[0]\n",
    "    idx_failure  = torch.where(failure_mask)[0]\n",
    "    idx_unknown  = torch.where(unknown_mask)[0]\n",
    "\n",
    "    result: Dict[str, Any] = {\n",
    "        'survival': int(survival_mask.sum().item()),\n",
    "        'failure' : int(failure_mask.sum().item()),\n",
    "        'unknown' : int(unknown_mask.sum().item()),\n",
    "        'idx_survival': idx_survival,\n",
    "        'idx_failure' : idx_failure,\n",
    "        'idx_unknown' : idx_unknown,\n",
    "    }\n",
    "\n",
    "    if return_masks:\n",
    "        result['mask_survival'] = survival_mask\n",
    "        result['mask_failure']  = failure_mask\n",
    "        result['mask_unknown']  = unknown_mask\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb564fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Dict, Any, Sequence, Optional\n",
    "from torch import Tensor\n",
    "\n",
    "def get_comp_cond_sys_prob(\n",
    "    rules_mat_surv: Tensor,\n",
    "    rules_mat_fail: Tensor,\n",
    "    probs: Tensor,\n",
    "    comps_st_cond: Dict[str, int],\n",
    "    row_names: Sequence[str],\n",
    "    s_fun,                          # Callable[[Dict[str,int]], tuple]\n",
    "    n_sample: int = 1_000_000,\n",
    "    n_batch:  int = 1_000_000,\n",
    "    *,\n",
    "    sys_row: Optional[int] = -1,    # index of the system row to exclude when building comps; set to None to include all\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    P(system state | given component states).\n",
    "\n",
    "    - 'probs' is (n_var, n_state) categorical; we condition rows listed in comps_st_cond to one-hot.\n",
    "    - We classify samples using rules; for unknowns we call s_fun(comps_dict) to resolve.\n",
    "    - Returns probabilities over {'survival','failure','unknown'} that sum ~ 1.0.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - If sys_row is not None, that row is excluded when building the comps dict for s_fun.\n",
    "      Default -1 means the last row is the system variable.\n",
    "    \"\"\"\n",
    "    # --- clone probs and apply conditioning ---\n",
    "    if torch.is_tensor(probs):\n",
    "        probs_cond = probs.clone()\n",
    "        n_comps, n_states = probs_cond.shape\n",
    "        n_vars = n_comps + 1 # system event\n",
    "    else:\n",
    "        raise TypeError(\"Expected 'probs' to be a torch.Tensor of shape (n_var, n_state).\")\n",
    "\n",
    "    if len(row_names) != n_vars:\n",
    "        raise ValueError(f\"row_names length ({len(row_names)}) must match probs rows ({n_vars}).\")\n",
    "\n",
    "    for x, s in comps_st_cond.items():\n",
    "        try:\n",
    "            row_idx = row_names.index(x)\n",
    "        except ValueError:\n",
    "            raise ValueError(f\"Component {x} not found in row_names.\")\n",
    "        if not (0 <= int(s) < n_states):\n",
    "            raise ValueError(f\"State {s} for component {x} is out of bounds [0,{n_states-1}].\")\n",
    "        probs_cond[row_idx].zero_()\n",
    "        probs_cond[row_idx, int(s)] = 1.0\n",
    "\n",
    "    # --- sampling loop (exactly n_sample draws) ---\n",
    "    batch_size = max(1, min(int(n_batch), int(n_sample)))\n",
    "    remaining = int(n_sample)\n",
    "\n",
    "    counts = {\"survival\": 0, \"failure\": 0, \"unknown\": 0}\n",
    "\n",
    "    while remaining > 0:\n",
    "        b = min(batch_size, remaining)\n",
    "        # IMPORTANT: sample from the *conditioned* probs\n",
    "        samples = tsum.sample_categorical(probs_cond, b)  # (b, n_var, n_state) one-hot\n",
    "\n",
    "        res = classify_samples_with_indices(\n",
    "            samples, rules_mat_surv, rules_mat_fail, return_masks=True\n",
    "        )\n",
    "\n",
    "        counts[\"survival\"] += int(res[\"survival\"])\n",
    "        counts[\"failure\"]  += int(res[\"failure\"])\n",
    "\n",
    "        # Resolve unknowns with s_fun\n",
    "        idx_unknown = res[\"idx_unknown\"]\n",
    "        if idx_unknown.numel() > 0:\n",
    "            # precompute the system row index if excluding\n",
    "            sys_idx = None\n",
    "            if sys_row is not None:\n",
    "                sys_idx = sys_row if sys_row >= 0 else (n_vars + sys_row)\n",
    "\n",
    "            for j in idx_unknown.tolist():\n",
    "                sample_j = samples[j]  # (n_var, n_state)\n",
    "                # convert one-hot row -> state index per var\n",
    "                states = torch.argmax(sample_j, dim=1).tolist()\n",
    "\n",
    "                # build comps dict for s_fun, excluding system row if requested\n",
    "                if sys_idx is not None:\n",
    "                    comps = {row_names[k]: int(states[k]) for k in range(n_vars) if k != sys_idx}\n",
    "                else:\n",
    "                    comps = {row_names[k]: int(states[k]) for k in range(n_vars)}\n",
    "\n",
    "                _, sys_st, _ = s_fun(comps)\n",
    "\n",
    "                if sys_st in (\"s\", \"survival\", 1, True):\n",
    "                    counts[\"survival\"] += 1\n",
    "                elif sys_st in (\"f\", \"failure\", 0, False):\n",
    "                    counts[\"failure\"] += 1\n",
    "\n",
    "        remaining -= b\n",
    "\n",
    "    # --- normalize to probabilities (denominator = requested n_sample) ---\n",
    "    total = float(n_sample)\n",
    "    cond_probs = {k: counts[k] / total for k in counts}\n",
    "    return cond_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a4ff936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jb622s\\AppData\\Local\\Temp\\ipykernel_20820\\384120129.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  rules_mat_surv = torch.load(r\"toy_tsum/rules_surv.pt\", map_location=\"cpu\")\n",
      "C:\\Users\\jb622s\\AppData\\Local\\Temp\\ipykernel_20820\\384120129.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  rules_mat_fail = torch.load(r\"toy_tsum/rules_fail.pt\", map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "TSUMPATH = Path(\"toy_tsum\") \n",
    "\n",
    "rules_mat_surv = torch.load(r\"toy_tsum/rules_surv.pt\", map_location=\"cpu\")\n",
    "rules_mat_surv = rules_mat_surv.to(device)\n",
    "rules_mat_fail = torch.load(r\"toy_tsum/rules_fail.pt\", map_location=\"cpu\")\n",
    "rules_mat_fail = rules_mat_fail.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9936aaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "row_names length (12) must match probs rows (11).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m pr_cond = \u001b[43mget_comp_cond_sys_prob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrules_mat_surv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrules_mat_fail\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcomps_st_cond\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43me01\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43me02\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrow_names\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43ms_fun\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_fun\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mget_comp_cond_sys_prob\u001b[39m\u001b[34m(rules_mat_surv, rules_mat_fail, probs, comps_st_cond, row_names, s_fun, n_sample, n_batch, sys_row)\u001b[39m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mExpected \u001b[39m\u001b[33m'\u001b[39m\u001b[33mprobs\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to be a torch.Tensor of shape (n_var, n_state).\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(row_names) != n_vars:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mrow_names length (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(row_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) must match probs rows (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_vars\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m).\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x, s \u001b[38;5;129;01min\u001b[39;00m comps_st_cond.items():\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: row_names length (12) must match probs rows (11)."
     ]
    }
   ],
   "source": [
    "pr_cond = get_comp_cond_sys_prob(\n",
    "    rules_mat_surv,\n",
    "    rules_mat_fail,\n",
    "    probs,\n",
    "    comps_st_cond = {'e01': 1, 'e02': 1},\n",
    "    row_names = row_names,\n",
    "    s_fun = s_fun\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38dadd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def get_comp_cond_sys_prob(rules_mat_surv, rules_mat_fail, probs, comps_st_cond, row_names, s_fun, n_sample = 1_000_000, n_batch = 1_000_000):\n",
    "    \"\"\"\n",
    "    Get conditional system survival/failure probabilities given component states: P(sys | comps_st_cond)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Update probs based on comps_st_cond\n",
    "    probs_cond = copy.deepcopy(probs)\n",
    "    for x, s in comps_st_cond.items():\n",
    "        if x not in row_names:\n",
    "            raise ValueError(f\"Component {x} not found in row_names.\")\n",
    "        row_idx = row_names.index(x)\n",
    "        if s < 0 or s >= probs.shape[1]:\n",
    "            raise ValueError(f\"State {s} for component {x} is out of bounds.\")\n",
    "        probs_cond[row_idx, :] = 0.0\n",
    "        probs_cond[row_idx, s] = 1.0\n",
    "    \n",
    "    sample_batch_size = min(n_sample, n_batch)\n",
    "    total_loops = max(n_sample // sample_batch_size, 1)\n",
    "    counts = {\"survival\": 0, \"failure\": 0, \"unknown\": 0}\n",
    "    for i in range(total_loops):\n",
    "        samples = tsum.sample_categorical(probs, sample_batch_size)\n",
    "        res = classify_samples_with_indices(samples, rules_mat_surv, rules_mat_fail, return_masks=True)\n",
    "\n",
    "        counts[\"survival\"] += res[\"survival\"]\n",
    "        counts[\"failure\"] += res[\"failure\"]\n",
    "\n",
    "        unknown_mask = res[\"mask_unknown\"]                   # BoolTensor[n_sample]\n",
    "        unknown_samples = samples[unknown_mask]              # (n_unknown, n_var, n_state)\n",
    "\n",
    "        for sample_j in unknown_samples:\n",
    "            states = torch.argmax(sample_j, dim=1).tolist()\n",
    "            comps = dict(zip(row_names[:-1], states[:-1])) # exclude system state\n",
    "            fval, sys_st, _ = s_fun(comps)\n",
    "\n",
    "            if sys_st == 's':\n",
    "                counts[\"survival\"] += 1\n",
    "            else:\n",
    "                counts[\"failure\"] += 1\n",
    "\n",
    "    cond_probs = {k: v / n_sample for k, v in counts.items()}\n",
    "\n",
    "    return cond_probs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
